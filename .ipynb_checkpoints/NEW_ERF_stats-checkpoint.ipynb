{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "023f31ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import os\n",
    "import os.path as op\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pickle\n",
    "from warnings import filterwarnings\n",
    "from sys import argv\n",
    "import matplotlib.pyplot as plt\n",
    "from stormdb.access import Query\n",
    "import src.group_stats as gs\n",
    "import importlib\n",
    "importlib.reload(gs)\n",
    "filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb632e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'MINDLAB2020_MEG-AuditoryPatternRecognition'\n",
    "project_dir = '/projects/' + project\n",
    "os.environ['MINDLABPROJ']= project\n",
    "os.environ['MNE_ROOT']= '~/miniconda3/envs/mne' # for surfer\n",
    "os.environ['MESA_GL_VERSION_OVERRIDE'] = '3.2'\n",
    "\n",
    "#avg_path = project_dir + '/scratch/working_memory/averages/data/'\n",
    "stats_dir = project_dir + '/scratch/working_memory/results/stats/'\n",
    "subs = np.arange(11,91) #[2,11,12,13,14,15,16]#np.arange(8) + 1\n",
    "exclude = np.array([15,30,32,33,51,55,60,63,73,82]) # subjects with low maintenance accuracy\n",
    "suffix = 'lf_0.05_hf_40_tstep_0.025_twin_0.05'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fb5a8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading subject 11\n",
      "loading subject 12\n",
      "loading subject 13\n",
      "loading subject 14\n",
      "loading subject 16\n",
      "loading subject 17\n",
      "loading subject 18\n",
      "loading subject 19\n",
      "loading subject 20\n",
      "loading subject 21\n",
      "loading subject 22\n",
      "loading subject 23\n",
      "could not load subject 0023_ZPC\n",
      "[Errno 2] No such file or directory: '/projects/MINDLAB2020_MEG-AuditoryPatternRecognition/scratch/working_memory/averages/data/0023_ZPC/0023_ZPC_evoked_lf_0.05_hf_40_tstep_0.025_twin_0.05.p'\n",
      "loading subject 24\n",
      "loading subject 25\n",
      "loading subject 26\n",
      "loading subject 27\n",
      "loading subject 28\n",
      "loading subject 29\n",
      "loading subject 31\n",
      "loading subject 34\n",
      "loading subject 35\n",
      "loading subject 36\n",
      "loading subject 37\n",
      "loading subject 38\n",
      "loading subject 39\n",
      "loading subject 40\n",
      "could not load subject 0040_LDN\n",
      "[Errno 2] No such file or directory: '/projects/MINDLAB2020_MEG-AuditoryPatternRecognition/scratch/working_memory/averages/data/0040_LDN/0040_LDN_evoked_lf_0.05_hf_40_tstep_0.025_twin_0.05.p'\n",
      "loading subject 41\n",
      "loading subject 42\n",
      "loading subject 43\n",
      "loading subject 44\n",
      "loading subject 45\n",
      "loading subject 46\n",
      "loading subject 47\n",
      "loading subject 48\n",
      "loading subject 49\n",
      "loading subject 50\n",
      "loading subject 52\n",
      "loading subject 53\n",
      "loading subject 54\n",
      "loading subject 56\n",
      "loading subject 57\n",
      "loading subject 58\n",
      "could not load subject 0058_L3X\n",
      "[Errno 2] No such file or directory: '/projects/MINDLAB2020_MEG-AuditoryPatternRecognition/scratch/working_memory/averages/data/0058_L3X/0058_L3X_evoked_lf_0.05_hf_40_tstep_0.025_twin_0.05.p'\n",
      "loading subject 59\n",
      "loading subject 61\n",
      "loading subject 62\n",
      "loading subject 64\n",
      "loading subject 65\n",
      "loading subject 66\n",
      "loading subject 67\n",
      "loading subject 68\n",
      "loading subject 69\n",
      "loading subject 70\n",
      "loading subject 71\n",
      "loading subject 72\n",
      "loading subject 74\n",
      "loading subject 75\n",
      "loading subject 76\n",
      "could not load subject 0076_E8Z\n",
      "[Errno 2] No such file or directory: '/projects/MINDLAB2020_MEG-AuditoryPatternRecognition/scratch/working_memory/averages/data/0076_E8Z/0076_E8Z_evoked_lf_0.05_hf_40_tstep_0.025_twin_0.05.p'\n",
      "loading subject 77\n",
      "loading subject 78\n",
      "loading subject 79\n",
      "loading subject 80\n",
      "loading subject 81\n",
      "loading subject 83\n",
      "loading subject 84\n",
      "loading subject 85\n",
      "loading subject 86\n",
      "loading subject 87\n",
      "loading subject 88\n",
      "loading subject 89\n",
      "loading subject 90\n",
      "converting to array\n",
      "converted to array\n",
      "loaded data for 66 subjects\n"
     ]
    }
   ],
   "source": [
    "sdata, scodes, times = gs.load_ERF_sensor(subs, suffix, exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbba48ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying common channels ...\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n"
     ]
    }
   ],
   "source": [
    "grand_avg = {}\n",
    "for e in sdata:\n",
    "    grand_avg[e] = mne.grand_average(sdata[e])\n",
    "    grand_avg[e].data = np.mean(np.array([cs.data for cs in sdata[e]]),0)\n",
    "    grand_avg[e].comment = sdata[e][0].comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2c5fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading adjacency matrix for neuromag306mag.\n",
      "Clustering.\n",
      "stat_fun(H1): min=-5.125833 max=4.673975\n",
      "Running initial clustering\n",
      "Found 31 clusters\n",
      "Permuting 499 times...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9846da01e3243bd9e61eca8e3033f87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          |  : 0/499 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conds = ['melody','melody_maintenance','melody_manipulation','block','interaction']\n",
    "stats_results, times = {}, {}\n",
    "ch_type = ['mag','grad']\n",
    "for ct in ch_type:\n",
    "    stats_results[ct], times[ct] = {}, {}\n",
    "    adjacency,_ = mne.channels.find_ch_adjacency(sdata['interaction'][0].info,ch_type=ct)\n",
    "    for c in conds:\n",
    "        X = np.array([cs.copy().pick_types(ct).crop(tmin=2,tmax=4).data for cs in sdata[c]])\n",
    "        times[ct][c] = sdata[c][0].copy().pick_types(ct).crop(tmin=2,tmax=4).times\n",
    "        stats_results[ct][c] = gs.do_stats(X, method='montecarlo', adjacency=adjacency, FDR_alpha=.025, h0=0,\n",
    "                                       cluster_alpha = .025, p_threshold = .05, n_permutations=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced8411a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#periods = {'encoding': [0,2], 'delay': [2,4]}#, 'retrieval': [4,6]}\n",
    "periods = {'all': [2,4]}#, 'delay': [2,4]}#, 'retrieval': [4,6]}\n",
    "# periods = {'encoding1': [0,.5],'encoding2': [.5,1],'encoding3': [1,1.5],'encoding4': [1.5,2], \n",
    "#            'delay1': [2,2.5],'delay2': [2.5,3],'delay3': [3,3.5],'delay4': [3.5,4]}#, 'retrieval': [4,6]}\n",
    "\n",
    "ch_type = ['mag','grad']\n",
    "vlims = {'mag': [-50,50],'grad': [0,13]}\n",
    "conds = ['melody_maintenance','melody_manipulation','interaction']\n",
    "for cht in ch_type:\n",
    "    print('\\n############### {} ################\\n'.format(cht))\n",
    "    for p in periods:\n",
    "        print('############# {} ################\\n'.format(p))\n",
    "        for c in conds:\n",
    "            tmin = periods[p][0]\n",
    "            tmax = periods[p][1]\n",
    "            cERF = grand_avg[c].copy()\n",
    "            tidx = np.where([x and y for x,y in zip(times[cht][c] >= tmin, times[cht][c] <= tmax)])[0]\n",
    "            cERF = cERF.pick_types(meg=cht).crop(tmin=tmin, tmax=tmax)\n",
    "\n",
    "#             cdata = stats_results[cht][c]['tvals'].copy()\n",
    "#             cdata = cdata[:,tidx]\n",
    "            cdata =  cERF.data\n",
    "            cmask = stats_results[cht][c]['mask'].copy()\n",
    "            cmask = cmask[:,tidx]\n",
    "            cERF.data = cdata*cmask\n",
    "            plot_times = np.arange(tmin,tmax,0.2)\n",
    "            print(c)\n",
    "            cERF.plot_topomap(times=plot_times, average = .2, vmin = vlims[cht][0], vmax = vlims[cht][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4891234",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
